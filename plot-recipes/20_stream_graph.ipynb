{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd41cca1",
   "metadata": {},
   "source": [
    "# Stream Graph - Flow and Temporal Evolution\n",
    "\n",
    "**Use Case**: Show how multiple categories change over time, emphasizing flow and continuity, stacked area visualization with organic appearance\n",
    "\n",
    "This notebook demonstrates how to create effective stream graphs for visualizing flowing data changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set3\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Stream graph visualization libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datasets for stream graphs\n",
    "# 1. Social Media Platform Usage Over Time\n",
    "years = np.arange(2010, 2024)\n",
    "n_years = len(years)\n",
    "\n",
    "# Define different social media platforms with realistic growth patterns\n",
    "platforms = {\n",
    "    'Facebook': {\n",
    "        'peak_year': 2016,\n",
    "        'max_users': 45,\n",
    "        'growth_rate': 0.8,\n",
    "        'decline_rate': 0.95\n",
    "    },\n",
    "    'Instagram': {\n",
    "        'peak_year': 2020,\n",
    "        'max_users': 35,\n",
    "        'growth_rate': 1.2,\n",
    "        'decline_rate': 0.98\n",
    "    },\n",
    "    'Twitter': {\n",
    "        'peak_year': 2018,\n",
    "        'max_users': 25,\n",
    "        'growth_rate': 0.6,\n",
    "        'decline_rate': 0.92\n",
    "    },\n",
    "    'TikTok': {\n",
    "        'peak_year': 2022,\n",
    "        'max_users': 40,\n",
    "        'growth_rate': 2.0,\n",
    "        'decline_rate': 1.0\n",
    "    },\n",
    "    'LinkedIn': {\n",
    "        'peak_year': 2021,\n",
    "        'max_users': 20,\n",
    "        'growth_rate': 0.4,\n",
    "        'decline_rate': 1.02\n",
    "    },\n",
    "    'YouTube': {\n",
    "        'peak_year': 2019,\n",
    "        'max_users': 30,\n",
    "        'growth_rate': 0.5,\n",
    "        'decline_rate': 1.01\n",
    "    }\n",
    "}\n",
    "\n",
    "social_media_data = []\n",
    "for year in years:\n",
    "    for platform, params in platforms.items():\n",
    "        # Calculate usage based on logistic-like growth and decline\n",
    "        years_from_start = year - 2010\n",
    "        years_from_peak = year - params['peak_year']\n",
    "        \n",
    "        if year <= params['peak_year']:\n",
    "            # Growth phase\n",
    "            usage = params['max_users'] * (1 / (1 + np.exp(-params['growth_rate'] * (years_from_start - 5))))\n",
    "        else:\n",
    "            # Decline or stabilization phase\n",
    "            peak_usage = params['max_users']\n",
    "            usage = peak_usage * (params['decline_rate'] ** abs(years_from_peak))\n",
    "        \n",
    "        # Add some noise\n",
    "        usage += np.random.normal(0, usage * 0.1)\n",
    "        usage = max(0, usage)  # Ensure non-negative\n",
    "        \n",
    "        social_media_data.append({\n",
    "            'Year': year,\n",
    "            'Platform': platform,\n",
    "            'Users': usage\n",
    "        })\n",
    "\n",
    "social_df = pd.DataFrame(social_media_data)\n",
    "\n",
    "# 2. Energy Source Mix Over Time\n",
    "energy_sources = {\n",
    "    'Coal': {\n",
    "        'start_pct': 40,\n",
    "        'end_pct': 15,\n",
    "        'peak_year': 2012,\n",
    "        'volatility': 2\n",
    "    },\n",
    "    'Natural Gas': {\n",
    "        'start_pct': 25,\n",
    "        'end_pct': 35,\n",
    "        'peak_year': 2020,\n",
    "        'volatility': 3\n",
    "    },\n",
    "    'Nuclear': {\n",
    "        'start_pct': 20,\n",
    "        'end_pct': 18,\n",
    "        'peak_year': 2015,\n",
    "        'volatility': 1\n",
    "    },\n",
    "    'Hydroelectric': {\n",
    "        'start_pct': 8,\n",
    "        'end_pct': 7,\n",
    "        'peak_year': 2016,\n",
    "        'volatility': 1.5\n",
    "    },\n",
    "    'Wind': {\n",
    "        'start_pct': 2,\n",
    "        'end_pct': 15,\n",
    "        'peak_year': 2023,\n",
    "        'volatility': 2.5\n",
    "    },\n",
    "    'Solar': {\n",
    "        'start_pct': 1,\n",
    "        'end_pct': 8,\n",
    "        'peak_year': 2023,\n",
    "        'volatility': 3\n",
    "    },\n",
    "    'Other Renewables': {\n",
    "        'start_pct': 4,\n",
    "        'end_pct': 2,\n",
    "        'peak_year': 2014,\n",
    "        'volatility': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "energy_data = []\n",
    "for year in years:\n",
    "    year_data = {}\n",
    "    total_percentage = 0\n",
    "    \n",
    "    for source, params in energy_sources.items():\n",
    "        # Calculate percentage based on transition from start to end\n",
    "        progress = (year - years[0]) / (years[-1] - years[0])\n",
    "        base_pct = params['start_pct'] + (params['end_pct'] - params['start_pct']) * progress\n",
    "        \n",
    "        # Add cyclical variation\n",
    "        cycle_effect = np.sin((year - years[0]) * 0.5) * params['volatility']\n",
    "        \n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, params['volatility'] * 0.3)\n",
    "        \n",
    "        percentage = base_pct + cycle_effect + noise\n",
    "        percentage = max(0.1, percentage)  # Minimum 0.1%\n",
    "        \n",
    "        year_data[source] = percentage\n",
    "        total_percentage += percentage\n",
    "    \n",
    "    # Normalize to 100%\n",
    "    for source in energy_sources.keys():\n",
    "        year_data[source] = (year_data[source] / total_percentage) * 100\n",
    "        \n",
    "        energy_data.append({\n",
    "            'Year': year,\n",
    "            'Source': source,\n",
    "            'Percentage': year_data[source]\n",
    "        })\n",
    "\n",
    "energy_df = pd.DataFrame(energy_data)\n",
    "\n",
    "# 3. Music Genre Popularity (Spotify-like streaming data)\n",
    "genres = ['Pop', 'Hip-Hop', 'Rock', 'Electronic', 'Country', 'Jazz', 'Classical', 'R&B', 'Folk', 'Reggae']\n",
    "months = pd.date_range('2020-01', '2023-12', freq='M')\n",
    "\n",
    "music_data = []\n",
    "for month in months:\n",
    "    # Seasonal effects for different genres\n",
    "    month_num = month.month\n",
    "    year = month.year\n",
    "    \n",
    "    seasonal_factors = {\n",
    "        'Pop': 1 + 0.2 * np.sin(2 * np.pi * month_num / 12),  # Summer peaks\n",
    "        'Hip-Hop': 1 + 0.15 * np.cos(2 * np.pi * month_num / 12),  # Winter peaks\n",
    "        'Rock': 1 + 0.1 * np.sin(2 * np.pi * month_num / 12 + np.pi/4),\n",
    "        'Electronic': 1 + 0.3 * np.sin(2 * np.pi * month_num / 12 + np.pi/2),  # Spring/Fall peaks\n",
    "        'Country': 1 + 0.2 * np.cos(2 * np.pi * month_num / 12 + np.pi/3),\n",
    "        'Jazz': 1 + 0.1 * np.cos(2 * np.pi * month_num / 12),\n",
    "        'Classical': 1 + 0.15 * np.cos(2 * np.pi * month_num / 12 + np.pi/6),\n",
    "        'R&B': 1 + 0.1 * np.sin(2 * np.pi * month_num / 12),\n",
    "        'Folk': 1 + 0.2 * np.sin(2 * np.pi * month_num / 12 + np.pi),  # Winter peaks\n",
    "        'Reggae': 1 + 0.25 * np.sin(2 * np.pi * month_num / 12)  # Summer peaks\n",
    "    }\n",
    "    \n",
    "    # Base popularity levels with trends\n",
    "    base_popularity = {\n",
    "        'Pop': 25 - (year - 2020) * 0.5,  # Slight decline\n",
    "        'Hip-Hop': 20 + (year - 2020) * 1.0,  # Growing\n",
    "        'Rock': 15 - (year - 2020) * 0.3,  # Declining\n",
    "        'Electronic': 12 + (year - 2020) * 0.8,  # Growing\n",
    "        'Country': 10 + (year - 2020) * 0.2,  # Stable\n",
    "        'Jazz': 5 - (year - 2020) * 0.1,  # Slight decline\n",
    "        'Classical': 4 - (year - 2020) * 0.1,\n",
    "        'R&B': 6 + (year - 2020) * 0.3,\n",
    "        'Folk': 2 + (year - 2020) * 0.1,\n",
    "        'Reggae': 3 + (year - 2020) * 0.0\n",
    "    }\n",
    "    \n",
    "    month_total = 0\n",
    "    month_data = {}\n",
    "    \n",
    "    for genre in genres:\n",
    "        popularity = (base_popularity[genre] * seasonal_factors[genre] + \n",
    "                     np.random.normal(0, 1))\n",
    "        popularity = max(0.5, popularity)  # Minimum popularity\n",
    "        month_data[genre] = popularity\n",
    "        month_total += popularity\n",
    "    \n",
    "    # Normalize to percentage\n",
    "    for genre in genres:\n",
    "        normalized_pct = (month_data[genre] / month_total) * 100\n",
    "        music_data.append({\n",
    "            'Month': month,\n",
    "            'Genre': genre,\n",
    "            'Popularity': normalized_pct\n",
    "        })\n",
    "\n",
    "music_df = pd.DataFrame(music_data)\n",
    "\n",
    "# 4. Economic Sector Employment Share\n",
    "sectors = ['Manufacturing', 'Services', 'Agriculture', 'Technology', 'Healthcare', 'Education', 'Retail', 'Construction']\n",
    "economic_years = np.arange(2000, 2024)\n",
    "\n",
    "sector_data = []\n",
    "for year in economic_years:\n",
    "    # Economic trends over time\n",
    "    year_progress = (year - 2000) / 23\n",
    "    \n",
    "    # Base employment shares with realistic trends\n",
    "    base_shares = {\n",
    "        'Manufacturing': 25 - 8 * year_progress,  # Declining\n",
    "        'Services': 30 + 5 * year_progress,  # Growing\n",
    "        'Agriculture': 8 - 3 * year_progress,  # Declining\n",
    "        'Technology': 5 + 12 * year_progress,  # Rapidly growing\n",
    "        'Healthcare': 8 + 4 * year_progress,  # Growing\n",
    "        'Education': 7 + 1 * year_progress,  # Slowly growing\n",
    "        'Retail': 12 - 2 * year_progress,  # Declining\n",
    "        'Construction': 5 - 1 * year_progress  # Slightly declining\n",
    "    }\n",
    "    \n",
    "    # Add economic cycle effects (boom/bust cycles)\n",
    "    cycle_phase = 2 * np.pi * (year - 2000) / 8  # 8-year economic cycles\n",
    "    cycle_strength = 2 * np.sin(cycle_phase)\n",
    "    \n",
    "    year_total = 0\n",
    "    year_shares = {}\n",
    "    \n",
    "    for sector, base_share in base_shares.items():\n",
    "        # Apply cycle effects differently to each sector\n",
    "        cycle_sensitivity = {\n",
    "            'Manufacturing': 1.5,\n",
    "            'Services': 0.8,\n",
    "            'Agriculture': 0.3,\n",
    "            'Technology': 1.2,\n",
    "            'Healthcare': 0.4,\n",
    "            'Education': 0.2,\n",
    "            'Retail': 1.0,\n",
    "            'Construction': 2.0\n",
    "        }\n",
    "        \n",
    "        adjusted_share = (base_share + \n",
    "                         cycle_strength * cycle_sensitivity[sector] + \n",
    "                         np.random.normal(0, 0.5))\n",
    "        adjusted_share = max(0.5, adjusted_share)  # Minimum share\n",
    "        \n",
    "        year_shares[sector] = adjusted_share\n",
    "        year_total += adjusted_share\n",
    "    \n",
    "    # Normalize to 100%\n",
    "    for sector in sectors:\n",
    "        normalized_share = (year_shares[sector] / year_total) * 100\n",
    "        sector_data.append({\n",
    "            'Year': year,\n",
    "            'Sector': sector,\n",
    "            'Employment_Share': normalized_share\n",
    "        })\n",
    "\n",
    "employment_df = pd.DataFrame(sector_data)\n",
    "\n",
    "# 5. Website Traffic Sources\n",
    "traffic_months = pd.date_range('2021-01', '2023-12', freq='M')\n",
    "traffic_sources = ['Organic Search', 'Paid Search', 'Social Media', 'Direct', 'Email', 'Referral']\n",
    "\n",
    "traffic_data = []\n",
    "for month in traffic_months:\n",
    "    month_num = month.month\n",
    "    year_progress = (month.year - 2021) + (month.month - 1) / 12\n",
    "    \n",
    "    # Base traffic shares with trends\n",
    "    base_traffic = {\n",
    "        'Organic Search': 40 - 2 * year_progress,  # Slightly declining\n",
    "        'Paid Search': 20 + 3 * year_progress,  # Growing investment\n",
    "        'Social Media': 15 + 5 * year_progress,  # Growing significantly\n",
    "        'Direct': 15 - 1 * year_progress,  # Slightly declining\n",
    "        'Email': 7 - 0.5 * year_progress,  # Declining\n",
    "        'Referral': 3 + 1 * year_progress  # Growing\n",
    "    }\n",
    "    \n",
    "    # Seasonal patterns\n",
    "    seasonal_effects = {\n",
    "        'Organic Search': 1 + 0.1 * np.cos(2 * np.pi * month_num / 12),\n",
    "        'Paid Search': 1 + 0.15 * np.sin(2 * np.pi * month_num / 12 + np.pi/2),  # Q4 campaigns\n",
    "        'Social Media': 1 + 0.2 * np.sin(2 * np.pi * month_num / 12),  # Summer activity\n",
    "        'Direct': 1 + 0.05 * np.cos(2 * np.pi * month_num / 12),\n",
    "        'Email': 1 + 0.1 * np.cos(2 * np.pi * month_num / 12 + np.pi/4),  # Holiday campaigns\n",
    "        'Referral': 1 + 0.08 * np.sin(2 * np.pi * month_num / 12)\n",
    "    }\n",
    "    \n",
    "    month_total = 0\n",
    "    month_traffic = {}\n",
    "    \n",
    "    for source, base_pct in base_traffic.items():\n",
    "        traffic_pct = (base_pct * seasonal_effects[source] + \n",
    "                      np.random.normal(0, 1))\n",
    "        traffic_pct = max(1, traffic_pct)  # Minimum 1%\n",
    "        month_traffic[source] = traffic_pct\n",
    "        month_total += traffic_pct\n",
    "    \n",
    "    # Normalize to 100%\n",
    "    for source in traffic_sources:\n",
    "        normalized_pct = (month_traffic[source] / month_total) * 100\n",
    "        traffic_data.append({\n",
    "            'Month': month,\n",
    "            'Source': source,\n",
    "            'Percentage': normalized_pct\n",
    "        })\n",
    "\n",
    "traffic_df = pd.DataFrame(traffic_data)\n",
    "\n",
    "print(\"Sample stream graph datasets created:\")\n",
    "print(f\"Social Media Usage: {len(social_df)} platform-year combinations\")\n",
    "print(f\"Energy Sources: {len(energy_df)} source-year combinations\")\n",
    "print(f\"Music Genres: {len(music_df)} genre-month combinations\")\n",
    "print(f\"Employment Sectors: {len(employment_df)} sector-year combinations\")\n",
    "print(f\"Website Traffic: {len(traffic_df)} source-month combinations\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nSample Social Media Data:\")\n",
    "print(social_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f95138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic stream graphs\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Stream Graph Visualizations - Flow and Temporal Evolution', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Social Media Platform Usage Stream Graph\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# Pivot data for stacked area plot\n",
    "social_pivot = social_df.pivot(index='Year', columns='Platform', values='Users').fillna(0)\n",
    "\n",
    "# Create stream graph with smooth curves\n",
    "x = social_pivot.index\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "# Use a more vibrant color palette\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(social_pivot.columns)))\n",
    "\n",
    "for i, platform in enumerate(social_pivot.columns):\n",
    "    y_values = social_pivot[platform].values\n",
    "    \n",
    "    # Smooth the curves using gaussian filter\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=0.8)\n",
    "    \n",
    "    ax1.fill_between(x, y_stack, y_stack + y_smooth, \n",
    "                    alpha=0.8, color=colors[i], label=platform, linewidth=0)\n",
    "    y_stack += y_smooth\n",
    "\n",
    "ax1.set_title('Social Media Platform Usage Evolution\\n(Million Users)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Users (Millions)')\n",
    "ax1.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Energy Source Mix Stream Graph  \n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "# Pivot energy data\n",
    "energy_pivot = energy_df.pivot(index='Year', columns='Source', values='Percentage').fillna(0)\n",
    "\n",
    "# Create centered stream graph (ThemeRiver style)\n",
    "x = energy_pivot.index\n",
    "baseline = np.zeros(len(x))\n",
    "\n",
    "# Calculate total and center the stream\n",
    "total_values = energy_pivot.sum(axis=1)\n",
    "y_stack = -total_values / 2  # Start from negative half\n",
    "\n",
    "energy_colors = plt.cm.tab10(np.linspace(0, 1, len(energy_pivot.columns)))\n",
    "\n",
    "for i, source in enumerate(['Coal', 'Natural Gas', 'Nuclear', 'Hydroelectric', 'Wind', 'Solar', 'Other Renewables']):\n",
    "    if source in energy_pivot.columns:\n",
    "        y_values = energy_pivot[source].values\n",
    "        y_smooth = gaussian_filter1d(y_values, sigma=0.6)\n",
    "        \n",
    "        ax2.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                        alpha=0.8, color=energy_colors[i], label=source, linewidth=0)\n",
    "        y_stack += y_smooth\n",
    "\n",
    "ax2.set_title('Energy Source Mix Evolution\\n(Percentage Share)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Percentage of Total Energy')\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# 3. Music Genre Popularity Stream Graph\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "# Convert month to numeric for plotting\n",
    "music_df['Month_Numeric'] = pd.to_datetime(music_df['Month']).astype(int) / 10**9 / (30*24*3600)  # Convert to months since epoch\n",
    "\n",
    "# Pivot music data\n",
    "music_pivot = music_df.pivot(index='Month', columns='Genre', values='Popularity').fillna(0)\n",
    "\n",
    "x = np.arange(len(music_pivot.index))\n",
    "x_labels = [month.strftime('%Y-%m') for month in music_pivot.index[::6]]  # Every 6 months\n",
    "x_tick_positions = np.arange(0, len(music_pivot.index), 6)\n",
    "\n",
    "# Create stream with different ordering for visual appeal\n",
    "genre_order = ['Pop', 'Hip-Hop', 'Electronic', 'Rock', 'Country', 'R&B', 'Jazz', 'Classical', 'Folk', 'Reggae']\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "music_colors = plt.cm.Spectral(np.linspace(0, 1, len(genre_order)))\n",
    "\n",
    "for i, genre in enumerate(genre_order):\n",
    "    if genre in music_pivot.columns:\n",
    "        y_values = music_pivot[genre].values\n",
    "        y_smooth = gaussian_filter1d(y_values, sigma=1.0)\n",
    "        \n",
    "        ax3.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                        alpha=0.8, color=music_colors[i], label=genre, linewidth=0)\n",
    "        y_stack += y_smooth\n",
    "\n",
    "ax3.set_title('Music Genre Popularity Streams\\n(Monthly Streaming Share)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Time Period')\n",
    "ax3.set_ylabel('Popularity Share (%)')\n",
    "ax3.set_xticks(x_tick_positions)\n",
    "ax3.set_xticklabels(x_labels, rotation=45)\n",
    "ax3.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Employment Sector Stream Graph\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Pivot employment data\n",
    "employment_pivot = employment_df.pivot(index='Year', columns='Sector', values='Employment_Share').fillna(0)\n",
    "\n",
    "x = employment_pivot.index\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "sector_colors = plt.cm.tab20(np.linspace(0, 1, len(employment_pivot.columns)))\n",
    "\n",
    "# Order sectors by average employment share for better visual hierarchy\n",
    "sector_means = employment_pivot.mean().sort_values(ascending=False)\n",
    "ordered_sectors = sector_means.index\n",
    "\n",
    "for i, sector in enumerate(ordered_sectors):\n",
    "    y_values = employment_pivot[sector].values\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=0.5)\n",
    "    \n",
    "    ax4.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                    alpha=0.8, color=sector_colors[i], label=sector, linewidth=0)\n",
    "    y_stack += y_smooth\n",
    "\n",
    "ax4.set_title('Economic Sector Employment Share\\n(Percentage of Workforce)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Year')\n",
    "ax4.set_ylabel('Employment Share (%)')\n",
    "ax4.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced stream graph techniques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Advanced Stream Graph Techniques', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Symmetric Stream Graph (ThemeRiver style)\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# Use traffic data for symmetric visualization\n",
    "traffic_pivot = traffic_df.pivot(index='Month', columns='Source', values='Percentage').fillna(0)\n",
    "\n",
    "x = np.arange(len(traffic_pivot.index))\n",
    "x_labels = [month.strftime('%Y-%m') for month in traffic_pivot.index[::6]]\n",
    "x_tick_positions = np.arange(0, len(traffic_pivot.index), 6)\n",
    "\n",
    "# Calculate the baseline for symmetric layout\n",
    "total_height = traffic_pivot.sum(axis=1)\n",
    "baseline = -total_height / 2\n",
    "\n",
    "# Create symmetric stream\n",
    "traffic_colors = plt.cm.viridis(np.linspace(0, 1, len(traffic_pivot.columns)))\n",
    "y_bottom = baseline.values\n",
    "y_top = baseline.values\n",
    "\n",
    "for i, source in enumerate(traffic_pivot.columns):\n",
    "    y_values = traffic_pivot[source].values\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=1.2)\n",
    "    \n",
    "    # Split the stream symmetrically\n",
    "    half_values = y_smooth / 2\n",
    "    \n",
    "    # Bottom half (negative)\n",
    "    ax1.fill_between(x, y_bottom, y_bottom - half_values,\n",
    "                    alpha=0.8, color=traffic_colors[i], linewidth=0)\n",
    "    \n",
    "    # Top half (positive)  \n",
    "    ax1.fill_between(x, y_top, y_top + half_values,\n",
    "                    alpha=0.8, color=traffic_colors[i], label=source, linewidth=0)\n",
    "    \n",
    "    y_bottom -= half_values\n",
    "    y_top += half_values\n",
    "\n",
    "ax1.set_title('Website Traffic Sources\\n(Symmetric ThemeRiver Layout)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Time Period')\n",
    "ax1.set_ylabel('Traffic Share (%)')\n",
    "ax1.set_xticks(x_tick_positions)\n",
    "ax1.set_xticklabels(x_labels, rotation=45)\n",
    "ax1.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Stream Graph with Trend Emphasis\n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "# Highlight specific categories in energy data\n",
    "energy_pivot = energy_df.pivot(index='Year', columns='Source', values='Percentage').fillna(0)\n",
    "\n",
    "x = energy_pivot.index\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "# Highlight renewable sources\n",
    "renewable_sources = ['Wind', 'Solar', 'Hydroelectric', 'Other Renewables']\n",
    "fossil_sources = ['Coal', 'Natural Gas']\n",
    "other_sources = ['Nuclear']\n",
    "\n",
    "# Different visual treatment for different categories\n",
    "for i, source in enumerate(energy_pivot.columns):\n",
    "    y_values = energy_pivot[source].values\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=0.6)\n",
    "    \n",
    "    if source in renewable_sources:\n",
    "        # Bright colors for renewables\n",
    "        color = plt.cm.Greens(0.4 + 0.6 * (renewable_sources.index(source) / len(renewable_sources)))\n",
    "        alpha = 0.9\n",
    "        linewidth = 1\n",
    "        edgecolor = 'darkgreen'\n",
    "    elif source in fossil_sources:\n",
    "        # Darker colors for fossil fuels\n",
    "        color = plt.cm.Reds(0.4 + 0.6 * (fossil_sources.index(source) / len(fossil_sources)))\n",
    "        alpha = 0.8\n",
    "        linewidth = 1\n",
    "        edgecolor = 'darkred'\n",
    "    else:\n",
    "        # Neutral color for nuclear\n",
    "        color = 'lightblue'\n",
    "        alpha = 0.7\n",
    "        linewidth = 1\n",
    "        edgecolor = 'navy'\n",
    "    \n",
    "    ax2.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                    alpha=alpha, color=color, label=source, \n",
    "                    linewidth=linewidth, edgecolor=edgecolor)\n",
    "    y_stack += y_smooth\n",
    "\n",
    "ax2.set_title('Energy Transition Visualization\\n(Renewables vs Fossil Fuels)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Energy Share (%)')\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend annotations\n",
    "ax2.annotate('Renewable Growth', xy=(2020, 75), xytext=(2018, 85),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
    "            fontsize=10, color='green', fontweight='bold')\n",
    "\n",
    "ax2.annotate('Coal Decline', xy=(2020, 20), xytext=(2016, 10),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "# 3. Multi-Scale Stream Graph\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "# Show both absolute and relative changes in social media data\n",
    "social_pivot = social_df.pivot(index='Year', columns='Platform', values='Users').fillna(0)\n",
    "\n",
    "# Normalize each platform's data to show relative growth\n",
    "social_normalized = social_pivot.div(social_pivot.iloc[0], axis=1) * 100  # Normalize to first year = 100\n",
    "\n",
    "x = social_normalized.index\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "# Create stream with varying transparency based on growth rate\n",
    "for i, platform in enumerate(social_normalized.columns):\n",
    "    y_values = social_normalized[platform].values\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=0.8)\n",
    "    \n",
    "    # Calculate growth rate for transparency\n",
    "    growth_rate = (y_values[-1] - y_values[0]) / y_values[0]\n",
    "    alpha = min(0.9, 0.4 + abs(growth_rate) / 3)  # More transparent for slower growth\n",
    "    \n",
    "    color = plt.cm.tab10(i / len(social_normalized.columns))\n",
    "    \n",
    "    ax3.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                    alpha=alpha, color=color, label=f'{platform} ({growth_rate:+.1%})', \n",
    "                    linewidth=1, edgecolor='white')\n",
    "    y_stack += y_smooth\n",
    "\n",
    "ax3.set_title('Social Media Platform Growth\\n(Relative to 2010 Baseline)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Relative Growth (2010 = 100)')\n",
    "ax3.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Stream Graph with Peak Highlighting\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Show employment sectors with peak periods highlighted\n",
    "employment_pivot = employment_df.pivot(index='Year', columns='Sector', values='Employment_Share').fillna(0)\n",
    "\n",
    "x = employment_pivot.index\n",
    "y_stack = np.zeros(len(x))\n",
    "\n",
    "# Calculate peaks for each sector\n",
    "sector_peaks = {}\n",
    "for sector in employment_pivot.columns:\n",
    "    peak_year = employment_pivot[sector].idxmax()\n",
    "    peak_value = employment_pivot[sector].max()\n",
    "    sector_peaks[sector] = {'year': peak_year, 'value': peak_value}\n",
    "\n",
    "sector_colors = plt.cm.tab20(np.linspace(0, 1, len(employment_pivot.columns)))\n",
    "\n",
    "for i, sector in enumerate(employment_pivot.columns):\n",
    "    y_values = employment_pivot[sector].values\n",
    "    y_smooth = gaussian_filter1d(y_values, sigma=0.5)\n",
    "    \n",
    "    # Base stream\n",
    "    ax4.fill_between(x, y_stack, y_stack + y_smooth,\n",
    "                    alpha=0.7, color=sector_colors[i], label=sector, linewidth=0)\n",
    "    \n",
    "    # Highlight peak period\n",
    "    peak_year = sector_peaks[sector]['year']\n",
    "    peak_idx = list(x).index(peak_year)\n",
    "    \n",
    "    # Create highlight around peak (±2 years)\n",
    "    highlight_start = max(0, peak_idx - 2)\n",
    "    highlight_end = min(len(x), peak_idx + 3)\n",
    "    \n",
    "    x_highlight = x[highlight_start:highlight_end]\n",
    "    y_bottom_highlight = y_stack[highlight_start:highlight_end]\n",
    "    y_top_highlight = (y_stack + y_smooth)[highlight_start:highlight_end]\n",
    "    \n",
    "    ax4.fill_between(x_highlight, y_bottom_highlight, y_top_highlight,\n",
    "                    alpha=0.9, color=sector_colors[i], linewidth=2, \n",
    "                    edgecolor='white')\n",
    "    \n",
    "    y_stack += y_smooth\n",
    "\n",
    "ax4.set_title('Employment Sector Peaks\\n(Peak Periods Highlighted)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Year')\n",
    "ax4.set_ylabel('Employment Share (%)')\n",
    "ax4.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive stream graphs (Plotly structure)\n",
    "print(\"Interactive Stream Graphs (Plotly):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. Basic Interactive Stream Graph\")\n",
    "print(\"Code structure:\")\n",
    "print(\"\"\"\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data in wide format\n",
    "df_pivot = data.pivot(index='time', columns='category', values='value')\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Create cumulative data for stacking\n",
    "x = df_pivot.index\n",
    "cumulative = np.zeros(len(x))\n",
    "\n",
    "for column in df_pivot.columns:\n",
    "    y_values = df_pivot[column].values\n",
    "    \n",
    "    # Add filled area\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=cumulative + y_values,\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(width=0),\n",
    "        showlegend=False,\n",
    "        name=column + '_top'\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=cumulative,\n",
    "        fill='tonexty' if column != df_pivot.columns[0] else 'tozeroy',\n",
    "        mode='lines',\n",
    "        line=dict(width=0),\n",
    "        name=column,\n",
    "        hovertemplate=\"<b>%{fullData.name}</b><br>\" +\n",
    "                      \"Time: %{x}<br>\" +\n",
    "                      \"Value: %{customdata}<br>\" +\n",
    "                      \"<extra></extra>\",\n",
    "        customdata=y_values\n",
    "    ))\n",
    "    \n",
    "    cumulative += y_values\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Stream Graph\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n2. Symmetric Stream Graph (ThemeRiver)\")\n",
    "print(\"Code structure:\")\n",
    "print(\"\"\"\n",
    "# Calculate symmetric baseline\n",
    "total_values = df_pivot.sum(axis=1)\n",
    "baseline = -total_values / 2\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "cumulative_bottom = baseline\n",
    "cumulative_top = baseline\n",
    "\n",
    "for column in df_pivot.columns:\n",
    "    y_values = df_pivot[column].values\n",
    "    half_values = y_values / 2\n",
    "    \n",
    "    # Bottom half\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=cumulative_bottom,\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(width=0),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=cumulative_bottom - half_values,\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(width=0),\n",
    "        name=column,\n",
    "        customdata=y_values\n",
    "    ))\n",
    "    \n",
    "    # Top half (same data, mirrored)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=cumulative_top + half_values,\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(width=0),\n",
    "        showlegend=False,\n",
    "        customdata=y_values\n",
    "    ))\n",
    "    \n",
    "    cumulative_bottom -= half_values\n",
    "    cumulative_top += half_values\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Symmetric Stream Graph (ThemeRiver)\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    shapes=[dict(type=\"line\", x0=x.min(), y0=0, x1=x.max(), y1=0,\n",
    "                 line=dict(color=\"black\", width=1, dash=\"dash\"))]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n3. Animated Stream Graph\")\n",
    "print(\"Code structure:\")\n",
    "print(\"\"\"\n",
    "# Create animation frames\n",
    "frames = []\n",
    "time_points = sorted(data['time'].unique())\n",
    "\n",
    "for i, time_point in enumerate(time_points):\n",
    "    # Get data up to current time point\n",
    "    current_data = data[data['time'] <= time_point]\n",
    "    df_current = current_data.pivot(index='time', columns='category', values='value')\n",
    "    \n",
    "    frame_traces = []\n",
    "    cumulative = np.zeros(len(df_current.index))\n",
    "    \n",
    "    for column in df_current.columns:\n",
    "        y_values = df_current[column].fillna(0).values\n",
    "        \n",
    "        frame_traces.append(go.Scatter(\n",
    "            x=df_current.index,\n",
    "            y=cumulative + y_values,\n",
    "            fill='tonexty' if column != df_current.columns[0] else 'tozeroy',\n",
    "            mode='lines',\n",
    "            line=dict(width=0),\n",
    "            name=column\n",
    "        ))\n",
    "        \n",
    "        cumulative += y_values\n",
    "    \n",
    "    frames.append(go.Frame(data=frame_traces, name=str(time_point)))\n",
    "\n",
    "# Create figure with first frame\n",
    "fig = go.Figure(data=frames[0].data, frames=frames)\n",
    "\n",
    "# Add animation controls\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\",\n",
    "             buttons=[dict(label=\"Play\", method=\"animate\", args=[None]),\n",
    "                      dict(label=\"Pause\", method=\"animate\", args=[[None]])])\n",
    "    ],\n",
    "    sliders=[dict(steps=[dict(args=[[f.name]], label=f.name, method=\"animate\")\n",
    "                        for f in frames])]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4. Multi-Layer Stream with Brushing\")\n",
    "print(\"Code structure:\")\n",
    "print(\"\"\"\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplot with secondary y-axis for different scales\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\"Absolute Values\", \"Percentage Share\"),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# Top plot: Absolute values\n",
    "cumulative_abs = np.zeros(len(x))\n",
    "for i, column in enumerate(df_pivot.columns):\n",
    "    y_abs = df_pivot[column].values\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, y=cumulative_abs + y_abs,\n",
    "        fill='tonexty' if i > 0 else 'tozeroy',\n",
    "        mode='lines', line=dict(width=0),\n",
    "        name=column, legendgroup=column,\n",
    "        customdata=y_abs\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    cumulative_abs += y_abs\n",
    "\n",
    "# Bottom plot: Percentage share\n",
    "df_pct = df_pivot.div(df_pivot.sum(axis=1), axis=0) * 100\n",
    "cumulative_pct = np.zeros(len(x))\n",
    "\n",
    "for i, column in enumerate(df_pct.columns):\n",
    "    y_pct = df_pct[column].values\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, y=cumulative_pct + y_pct,\n",
    "        fill='tonexty' if i > 0 else 'tozeroy',\n",
    "        mode='lines', line=dict(width=0),\n",
    "        name=column, legendgroup=column,\n",
    "        showlegend=False,\n",
    "        customdata=y_pct\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    cumulative_pct += y_pct\n",
    "\n",
    "# Add crossfilter behavior\n",
    "fig.update_layout(\n",
    "    title=\"Multi-Scale Stream Analysis\",\n",
    "    hovermode='x unified',\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis of stream graph data\n",
    "print(\"Stream Graph Statistical Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Trend Analysis for Social Media Platforms\n",
    "print(\"1. SOCIAL MEDIA PLATFORM TREND ANALYSIS:\")\n",
    "\n",
    "social_pivot = social_df.pivot(index='Year', columns='Platform', values='Users').fillna(0)\n",
    "\n",
    "print(\"   Platform Growth Analysis:\")\n",
    "for platform in social_pivot.columns:\n",
    "    platform_data = social_pivot[platform]\n",
    "    \n",
    "    # Calculate growth metrics\n",
    "    initial_users = platform_data.iloc[0]\n",
    "    final_users = platform_data.iloc[-1]\n",
    "    peak_users = platform_data.max()\n",
    "    peak_year = platform_data.idxmax()\n",
    "    \n",
    "    # Growth rates\n",
    "    total_growth = ((final_users - initial_users) / initial_users * 100) if initial_users > 0 else 0\n",
    "    cagr = ((final_users / initial_users) ** (1 / (len(platform_data) - 1)) - 1) * 100 if initial_users > 0 else 0\n",
    "    \n",
    "    # Volatility (coefficient of variation)\n",
    "    volatility = (platform_data.std() / platform_data.mean()) * 100\n",
    "    \n",
    "    # Trend classification\n",
    "    if total_growth > 100:\n",
    "        trend = \"High Growth\"\n",
    "    elif total_growth > 20:\n",
    "        trend = \"Moderate Growth\"\n",
    "    elif total_growth > -10:\n",
    "        trend = \"Stable\"\n",
    "    else:\n",
    "        trend = \"Declining\"\n",
    "    \n",
    "    print(f\"\\n     {platform}:\")\n",
    "    print(f\"       Total Growth: {total_growth:+.1f}%\")\n",
    "    print(f\"       CAGR: {cagr:+.1f}%\")\n",
    "    print(f\"       Peak: {peak_users:.1f}M users ({peak_year})\")\n",
    "    print(f\"       Volatility: {volatility:.1f}%\")\n",
    "    print(f\"       Trend: {trend}\")\n",
    "\n",
    "# Platform market share evolution\n",
    "print(f\"\\n   Market Share Evolution:\")\n",
    "social_totals = social_pivot.sum(axis=1)\n",
    "social_share = social_pivot.div(social_totals, axis=0) * 100\n",
    "\n",
    "# Market concentration (Herfindahl-Hirschman Index)\n",
    "hhi_by_year = {}\n",
    "for year in social_share.index:\n",
    "    year_shares = social_share.loc[year]\n",
    "    hhi = sum(share ** 2 for share in year_shares)\n",
    "    hhi_by_year[year] = hhi\n",
    "\n",
    "initial_hhi = hhi_by_year[social_share.index[0]]\n",
    "final_hhi = hhi_by_year[social_share.index[-1]]\n",
    "market_concentration_change = ((final_hhi - initial_hhi) / initial_hhi) * 100\n",
    "\n",
    "concentration_level = \"High\" if final_hhi > 2500 else \"Moderate\" if final_hhi > 1500 else \"Low\"\n",
    "\n",
    "print(f\"     Market Concentration (HHI): {final_hhi:.0f} ({concentration_level})\")\n",
    "print(f\"     Concentration Change: {market_concentration_change:+.1f}%\")\n",
    "\n",
    "# 2. Energy Transition Analysis\n",
    "print(f\"\\n2. ENERGY TRANSITION ANALYSIS:\")\n",
    "\n",
    "energy_pivot = energy_df.pivot(index='Year', columns='Source', values='Percentage').fillna(0)\n",
    "\n",
    "# Categorize energy sources\n",
    "renewable_sources = ['Wind', 'Solar', 'Hydroelectric', 'Other Renewables']\n",
    "fossil_sources = ['Coal', 'Natural Gas'] \n",
    "nuclear_sources = ['Nuclear']\n",
    "\n",
    "# Calculate category totals\n",
    "renewables_total = energy_pivot[renewable_sources].sum(axis=1)\n",
    "fossils_total = energy_pivot[fossil_sources].sum(axis=1)\n",
    "nuclear_total = energy_pivot[nuclear_sources].sum(axis=1)\n",
    "\n",
    "print(\"   Energy Source Category Analysis:\")\n",
    "\n",
    "# Renewable energy growth\n",
    "renewables_growth = ((renewables_total.iloc[-1] - renewables_total.iloc[0]) / renewables_total.iloc[0]) * 100\n",
    "renewables_cagr = ((renewables_total.iloc[-1] / renewables_total.iloc[0]) ** (1 / (len(renewables_total) - 1)) - 1) * 100\n",
    "\n",
    "print(f\"     Renewable Energy:\")\n",
    "print(f\"       Share Growth: {renewables_growth:+.1f}%\")\n",
    "print(f\"       CAGR: {renewables_cagr:+.1f}%\")\n",
    "print(f\"       Current Share: {renewables_total.iloc[-1]:.1f}%\")\n",
    "\n",
    "# Fossil fuel decline\n",
    "fossils_decline = ((fossils_total.iloc[-1] - fossils_total.iloc[0]) / fossils_total.iloc[0]) * 100\n",
    "fossils_cagr = ((fossils_total.iloc[-1] / fossils_total.iloc[0]) ** (1 / (len(fossils_total) - 1)) - 1) * 100\n",
    "\n",
    "print(f\"     Fossil Fuels:\")\n",
    "print(f\"       Share Change: {fossils_decline:+.1f}%\")\n",
    "print(f\"       CAGR: {fossils_cagr:+.1f}%\")\n",
    "print(f\"       Current Share: {fossils_total.iloc[-1]:.1f}%\")\n",
    "\n",
    "# Transition speed analysis\n",
    "transition_years = len(energy_pivot.index)\n",
    "years_to_majority_renewables = None\n",
    "\n",
    "for i, year in enumerate(renewables_total.index):\n",
    "    if renewables_total.iloc[i] > 50:\n",
    "        years_to_majority_renewables = year\n",
    "        break\n",
    "\n",
    "if years_to_majority_renewables:\n",
    "    print(f\"     Renewable Majority Achieved: {years_to_majority_renewables}\")\n",
    "else:\n",
    "    # Project when renewables might reach majority\n",
    "    if renewables_cagr > 0:\n",
    "        years_needed = np.log(50 / renewables_total.iloc[-1]) / np.log(1 + renewables_cagr / 100)\n",
    "        projected_year = renewables_total.index[-1] + years_needed\n",
    "        print(f\"     Projected Renewable Majority: ~{projected_year:.0f}\")\n",
    "    else:\n",
    "        print(\"     Renewable Majority: Not projected with current trends\")\n",
    "\n",
    "# 3. Music Genre Seasonality Analysis\n",
    "print(f\"\\n3. MUSIC GENRE SEASONALITY ANALYSIS:\")\n",
    "\n",
    "music_df['Month_Num'] = pd.to_datetime(music_df['Month']).dt.month\n",
    "\n",
    "print(\"   Seasonal Patterns by Genre:\")\n",
    "for genre in genres[:6]:  # Top 6 genres for brevity\n",
    "    genre_data = music_df[music_df['Genre'] == genre]\n",
    "    \n",
    "    # Calculate seasonal variation\n",
    "    monthly_avg = genre_data.groupby('Month_Num')['Popularity'].mean()\n",
    "    seasonal_range = monthly_avg.max() - monthly_avg.min()\n",
    "    seasonal_coefficient = (monthly_avg.std() / monthly_avg.mean()) * 100\n",
    "    \n",
    "    # Find peak and trough months\n",
    "    peak_month = monthly_avg.idxmax()\n",
    "    trough_month = monthly_avg.idxmin()\n",
    "    \n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    seasonality_level = \"High\" if seasonal_coefficient > 15 else \"Moderate\" if seasonal_coefficient > 8 else \"Low\"\n",
    "    \n",
    "    print(f\"\\n     {genre}:\")\n",
    "    print(f\"       Seasonal Variation: {seasonal_range:.1f}%\")\n",
    "    print(f\"       Seasonality: {seasonality_level} (CV: {seasonal_coefficient:.1f}%)\")\n",
    "    print(f\"       Peak Month: {month_names[peak_month-1]} ({monthly_avg.iloc[peak_month-1]:.1f}%)\")\n",
    "    print(f\"       Trough Month: {month_names[trough_month-1]} ({monthly_avg.iloc[trough_month-1]:.1f}%)\")\n",
    "\n",
    "# 4. Employment Sector Stability Analysis\n",
    "print(f\"\\n4. EMPLOYMENT SECTOR STABILITY ANALYSIS:\")\n",
    "\n",
    "employment_pivot = employment_df.pivot(index='Year', columns='Sector', values='Employment_Share').fillna(0)\n",
    "\n",
    "print(\"   Sector Stability Metrics:\")\n",
    "for sector in employment_pivot.columns:\n",
    "    sector_data = employment_pivot[sector]\n",
    "    \n",
    "    # Stability metrics\n",
    "    mean_share = sector_data.mean()\n",
    "    volatility = sector_data.std()\n",
    "    coefficient_variation = (volatility / mean_share) * 100\n",
    "    \n",
    "    # Trend analysis\n",
    "    correlation_with_time = np.corrcoef(range(len(sector_data)), sector_data)[0, 1]\n",
    "    \n",
    "    # Economic cycle sensitivity (correlation with a simulated economic cycle)\n",
    "    economic_cycle = np.sin(2 * np.pi * np.arange(len(sector_data)) / 8)  # 8-year cycle\n",
    "    cycle_correlation = np.corrcoef(economic_cycle, sector_data)[0, 1]\n",
    "    \n",
    "    # Classifications\n",
    "    if coefficient_variation < 10:\n",
    "        stability = \"Very Stable\"\n",
    "    elif coefficient_variation < 20:\n",
    "        stability = \"Stable\"\n",
    "    elif coefficient_variation < 30:\n",
    "        stability = \"Moderate\"\n",
    "    else:\n",
    "        stability = \"Volatile\"\n",
    "    \n",
    "    if abs(correlation_with_time) > 0.7:\n",
    "        trend_strength = \"Strong\"\n",
    "    elif abs(correlation_with_time) > 0.4:\n",
    "        trend_strength = \"Moderate\"\n",
    "    else:\n",
    "        trend_strength = \"Weak\"\n",
    "    \n",
    "    trend_direction = \"Growing\" if correlation_with_time > 0 else \"Declining\" if correlation_with_time < 0 else \"Stable\"\n",
    "    \n",
    "    print(f\"\\n     {sector}:\")\n",
    "    print(f\"       Mean Share: {mean_share:.1f}%\")\n",
    "    print(f\"       Stability: {stability} (CV: {coefficient_variation:.1f}%)\")\n",
    "    print(f\"       Trend: {trend_strength} {trend_direction}\")\n",
    "    print(f\"       Cycle Sensitivity: {abs(cycle_correlation):.2f}\")\n",
    "\n",
    "# 5. Stream Graph Design Effectiveness Analysis\n",
    "print(f\"\\n5. STREAM GRAPH DESIGN ANALYSIS:\")\n",
    "\n",
    "print(\"   Data Characteristics Assessment:\")\n",
    "datasets = {\n",
    "    'Social Media Usage': {\n",
    "        'temporal_span': len(social_pivot.index),\n",
    "        'categories': len(social_pivot.columns),\n",
    "        'value_range': social_pivot.max().max() - social_pivot.min().min(),\n",
    "        'stacking_suitability': 'Excellent',\n",
    "        'trend_clarity': 'High'\n",
    "    },\n",
    "    'Energy Sources': {\n",
    "        'temporal_span': len(energy_pivot.index),\n",
    "        'categories': len(energy_pivot.columns),\n",
    "        'value_range': 100,  # Percentages\n",
    "        'stacking_suitability': 'Perfect',\n",
    "        'trend_clarity': 'Very High'\n",
    "    },\n",
    "    'Music Genres': {\n",
    "        'temporal_span': len(music_df['Month'].unique()),\n",
    "        'categories': len(genres),\n",
    "        'value_range': 100,  # Percentages\n",
    "        'stacking_suitability': 'Good',\n",
    "        'trend_clarity': 'Moderate'\n",
    "    },\n",
    "    'Employment Sectors': {\n",
    "        'temporal_span': len(employment_pivot.index),\n",
    "        'categories': len(employment_pivot.columns),\n",
    "        'value_range': 100,  # Percentages\n",
    "        'stacking_suitability': 'Excellent',\n",
    "        'trend_clarity': 'High'\n",
    "    }\n",
    "}\n",
    "\n",
    "for dataset, props in datasets.items():\n",
    "    print(f\"\\n     {dataset}:\")\n",
    "    print(f\"       Time Points: {props['temporal_span']}\")\n",
    "    print(f\"       Categories: {props['categories']}\")\n",
    "    print(f\"       Stacking Suitability: {props['stacking_suitability']}\")\n",
    "    print(f\"       Trend Clarity: {props['trend_clarity']}\")\n",
    "\n",
    "print(f\"\\n   Stream Graph Best Practices:\")\n",
    "print(\"   ✓ Use for 3-15 categories (too few = underutilized, too many = cluttered)\")\n",
    "print(\"   ✓ Ideal for percentage/proportion data that sum to 100%\")\n",
    "print(\"   ✓ Minimum 10-20 time points for smooth curves\")\n",
    "print(\"   ✓ Apply smoothing (Gaussian filter) for organic appearance\")\n",
    "print(\"   ✓ Order categories by size or importance for visual hierarchy\")\n",
    "print(\"   ✓ Use symmetric layout (ThemeRiver) for balanced comparison\")\n",
    "print(\"   ✓ Consider interactive features for detailed exploration\")\n",
    "\n",
    "print(f\"\\nWhen to Use Stream Graphs:\")\n",
    "print(\"   • Market share evolution over time\")\n",
    "print(\"   • Budget allocation changes\")\n",
    "print(\"   • Population demographics shifts\")\n",
    "print(\"   • Resource consumption patterns\")\n",
    "print(\"   • Technology adoption curves\")\n",
    "print(\"   • Genre/category popularity trends\")\n",
    "\n",
    "print(f\"\\nAlternatives to Consider:\")\n",
    "print(\"   • Stacked area charts for simpler rectangular appearance\")\n",
    "print(\"   • Sankey diagrams for flow between specific time points\")\n",
    "print(\"   • Alluvial plots for categorical flow visualization\")\n",
    "print(\"   • Multi-line charts when absolute values matter more than proportions\")\n",
    "print(\"   • Animated bar charts for dramatic category changes\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
