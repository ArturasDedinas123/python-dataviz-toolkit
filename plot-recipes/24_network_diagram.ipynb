{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571a7546",
   "metadata": {},
   "source": [
    "# Network Diagram - Relationship Visualization\n",
    "\n",
    "**Use Case**: Visualize relationships, connections, networks (social networks, organizational charts, system dependencies)\n",
    "\n",
    "This notebook demonstrates how to create effective network diagrams for analyzing relationships and connections between entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Network visualization libraries loaded!\")\n",
    "print(\"Note: For advanced network analysis, consider installing: pip install networkx python-louvain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample network datasets\n",
    "# 1. Social Network - Company employees\n",
    "employees = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry', 'Iris', 'Jack']\n",
    "departments = ['Engineering', 'Marketing', 'Sales', 'HR', 'Finance']\n",
    "\n",
    "# Create employee relationships (who works with whom)\n",
    "social_connections = [\n",
    "    ('Alice', 'Bob', 'Engineering', 8),      # (person1, person2, relationship_type, strength)\n",
    "    ('Alice', 'Charlie', 'Engineering', 9),\n",
    "    ('Bob', 'Charlie', 'Engineering', 7),\n",
    "    ('Diana', 'Eve', 'Marketing', 6),\n",
    "    ('Diana', 'Frank', 'Cross-dept', 4),\n",
    "    ('Eve', 'Grace', 'Marketing', 8),\n",
    "    ('Frank', 'Henry', 'Sales', 7),\n",
    "    ('Grace', 'Iris', 'Cross-dept', 5),\n",
    "    ('Henry', 'Jack', 'Sales', 6),\n",
    "    ('Alice', 'Diana', 'Cross-dept', 3),\n",
    "    ('Charlie', 'Frank', 'Cross-dept', 4),\n",
    "    ('Bob', 'Grace', 'Cross-dept', 2),\n",
    "    ('Eve', 'Henry', 'Cross-dept', 3),\n",
    "    ('Iris', 'Jack', 'Cross-dept', 5)\n",
    "]\n",
    "\n",
    "social_df = pd.DataFrame(social_connections, columns=['person1', 'person2', 'relationship', 'strength'])\n",
    "\n",
    "# 2. Technology Stack Dependencies\n",
    "tech_dependencies = [\n",
    "    ('Frontend', 'API Gateway', 'depends_on', 1),\n",
    "    ('API Gateway', 'Auth Service', 'depends_on', 1),\n",
    "    ('API Gateway', 'User Service', 'depends_on', 1),\n",
    "    ('API Gateway', 'Order Service', 'depends_on', 1),\n",
    "    ('User Service', 'User Database', 'depends_on', 1),\n",
    "    ('Order Service', 'Order Database', 'depends_on', 1),\n",
    "    ('Order Service', 'Payment Service', 'depends_on', 1),\n",
    "    ('Payment Service', 'Payment Database', 'depends_on', 1),\n",
    "    ('Auth Service', 'Auth Database', 'depends_on', 1),\n",
    "    ('User Service', 'Cache', 'depends_on', 1),\n",
    "    ('Order Service', 'Message Queue', 'depends_on', 1),\n",
    "    ('Payment Service', 'External API', 'depends_on', 1),\n",
    "    ('Message Queue', 'Notification Service', 'triggers', 1),\n",
    "    ('Notification Service', 'Email Service', 'depends_on', 1)\n",
    "]\n",
    "\n",
    "tech_df = pd.DataFrame(tech_dependencies, columns=['source', 'target', 'relationship', 'weight'])\n",
    "\n",
    "# 3. Academic Citation Network\n",
    "papers = ['Paper A', 'Paper B', 'Paper C', 'Paper D', 'Paper E', 'Paper F', 'Paper G', 'Paper H']\n",
    "citations = [\n",
    "    ('Paper A', 'Paper B', 3),  # (citing_paper, cited_paper, citation_count)\n",
    "    ('Paper A', 'Paper C', 2),\n",
    "    ('Paper B', 'Paper D', 4),\n",
    "    ('Paper B', 'Paper E', 1),\n",
    "    ('Paper C', 'Paper D', 2),\n",
    "    ('Paper C', 'Paper F', 3),\n",
    "    ('Paper D', 'Paper G', 5),\n",
    "    ('Paper E', 'Paper F', 2),\n",
    "    ('Paper F', 'Paper G', 3),\n",
    "    ('Paper F', 'Paper H', 1),\n",
    "    ('Paper G', 'Paper H', 2)\n",
    "]\n",
    "\n",
    "citation_df = pd.DataFrame(citations, columns=['citing', 'cited', 'count'])\n",
    "\n",
    "print(\"Sample network datasets created:\")\n",
    "print(f\"Social Network: {len(social_df)} connections between {len(employees)} employees\")\n",
    "print(f\"Tech Dependencies: {len(tech_df)} dependencies between services\")\n",
    "print(f\"Citation Network: {len(citation_df)} citations between {len(papers)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic network visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Network Diagram Visualizations', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Social Network - Employee Connections\n",
    "ax1 = axes[0, 0]\n",
    "G_social = nx.Graph()\n",
    "\n",
    "# Add edges with weights\n",
    "for _, row in social_df.iterrows():\n",
    "    G_social.add_edge(row['person1'], row['person2'], \n",
    "                     weight=row['strength'], relationship=row['relationship'])\n",
    "\n",
    "# Create layout\n",
    "pos_social = nx.spring_layout(G_social, k=3, iterations=50)\n",
    "\n",
    "# Draw edges with different colors by relationship type\n",
    "relationship_colors = {'Engineering': 'blue', 'Marketing': 'red', 'Sales': 'green', 'Cross-dept': 'gray'}\n",
    "for _, row in social_df.iterrows():\n",
    "    edge_color = relationship_colors[row['relationship']]\n",
    "    edge_width = row['strength'] / 2  # Scale edge width by strength\n",
    "    nx.draw_networkx_edges(G_social, pos_social, \n",
    "                          edgelist=[(row['person1'], row['person2'])],\n",
    "                          edge_color=edge_color, width=edge_width, alpha=0.7, ax=ax1)\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G_social, pos_social, node_color='lightblue',\n",
    "                      node_size=800, alpha=0.9, ax=ax1)\n",
    "nx.draw_networkx_labels(G_social, pos_social, font_size=8, font_weight='bold', ax=ax1)\n",
    "\n",
    "ax1.set_title('Employee Social Network\\n(Edge color = dept, width = relationship strength)')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], color=color, lw=3, label=dept) \n",
    "                  for dept, color in relationship_colors.items()]\n",
    "ax1.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# 2. Technology Dependency Graph\n",
    "ax2 = axes[0, 1]\n",
    "G_tech = nx.DiGraph()  # Directed graph for dependencies\n",
    "\n",
    "# Add edges\n",
    "for _, row in tech_df.iterrows():\n",
    "    G_tech.add_edge(row['source'], row['target'], relationship=row['relationship'])\n",
    "\n",
    "# Create hierarchical layout\n",
    "pos_tech = nx.spring_layout(G_tech, k=2, iterations=50)\n",
    "\n",
    "# Draw edges with arrows\n",
    "nx.draw_networkx_edges(G_tech, pos_tech, edge_color='darkblue',\n",
    "                      arrows=True, arrowsize=20, arrowstyle='->', \n",
    "                      width=2, alpha=0.7, ax=ax2)\n",
    "\n",
    "# Color nodes by type\n",
    "node_types = {\n",
    "    'Frontend': 'lightgreen',\n",
    "    'API Gateway': 'orange',\n",
    "    'Auth Service': 'lightcoral',\n",
    "    'User Service': 'lightcoral',\n",
    "    'Order Service': 'lightcoral',\n",
    "    'Payment Service': 'lightcoral',\n",
    "    'Notification Service': 'lightcoral',\n",
    "    'Email Service': 'lightcoral',\n",
    "    'User Database': 'lightgray',\n",
    "    'Order Database': 'lightgray',\n",
    "    'Payment Database': 'lightgray',\n",
    "    'Auth Database': 'lightgray',\n",
    "    'Cache': 'yellow',\n",
    "    'Message Queue': 'yellow',\n",
    "    'External API': 'pink'\n",
    "}\n",
    "\n",
    "node_colors = [node_types.get(node, 'lightblue') for node in G_tech.nodes()]\n",
    "nx.draw_networkx_nodes(G_tech, pos_tech, node_color=node_colors,\n",
    "                      node_size=1000, alpha=0.9, ax=ax2)\n",
    "\n",
    "# Draw labels with smaller font\n",
    "nx.draw_networkx_labels(G_tech, pos_tech, font_size=7, font_weight='bold', ax=ax2)\n",
    "\n",
    "ax2.set_title('Technology Stack Dependencies\\n(Arrows show dependency direction)')\n",
    "ax2.axis('off')\n",
    "\n",
    "# 3. Citation Network\n",
    "ax3 = axes[1, 0]\n",
    "G_citation = nx.DiGraph()\n",
    "\n",
    "# Add edges with citation counts as weights\n",
    "for _, row in citation_df.iterrows():\n",
    "    G_citation.add_edge(row['citing'], row['cited'], weight=row['count'])\n",
    "\n",
    "pos_citation = nx.spring_layout(G_citation, k=2, iterations=50)\n",
    "\n",
    "# Draw edges with width proportional to citation count\n",
    "edges = G_citation.edges()\n",
    "weights = [G_citation[u][v]['weight'] for u, v in edges]\n",
    "nx.draw_networkx_edges(G_citation, pos_citation, \n",
    "                      width=[w*2 for w in weights],\n",
    "                      edge_color='purple', arrows=True, arrowsize=15,\n",
    "                      arrowstyle='->', alpha=0.7, ax=ax3)\n",
    "\n",
    "# Size nodes by in-degree (how many times cited)\n",
    "in_degrees = dict(G_citation.in_degree())\n",
    "node_sizes = [in_degrees[node] * 200 + 300 for node in G_citation.nodes()]\n",
    "\n",
    "nx.draw_networkx_nodes(G_citation, pos_citation, \n",
    "                      node_size=node_sizes, node_color='lightcyan',\n",
    "                      alpha=0.9, ax=ax3)\n",
    "nx.draw_networkx_labels(G_citation, pos_citation, font_size=8, font_weight='bold', ax=ax3)\n",
    "\n",
    "ax3.set_title('Academic Citation Network\\n(Node size = citations received, edge width = citation frequency)')\n",
    "ax3.axis('off')\n",
    "\n",
    "# 4. Network metrics visualization\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Calculate various network metrics for social network\n",
    "degree_centrality = nx.degree_centrality(G_social)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_social)\n",
    "closeness_centrality = nx.closeness_centrality(G_social)\n",
    "\n",
    "# Create metrics dataframe\n",
    "metrics_data = []\n",
    "for node in G_social.nodes():\n",
    "    metrics_data.append({\n",
    "        'person': node,\n",
    "        'degree': degree_centrality[node],\n",
    "        'betweenness': betweenness_centrality[node],\n",
    "        'closeness': closeness_centrality[node]\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Plot centrality measures\n",
    "x_pos = range(len(metrics_df))\n",
    "width = 0.25\n",
    "\n",
    "ax4.bar([x - width for x in x_pos], metrics_df['degree'], width, \n",
    "        label='Degree Centrality', alpha=0.8)\n",
    "ax4.bar(x_pos, metrics_df['betweenness'], width, \n",
    "        label='Betweenness Centrality', alpha=0.8)\n",
    "ax4.bar([x + width for x in x_pos], metrics_df['closeness'], width, \n",
    "        label='Closeness Centrality', alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Employees')\n",
    "ax4.set_ylabel('Centrality Score')\n",
    "ax4.set_title('Network Centrality Measures\\n(Social Network)')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(metrics_df['person'], rotation=45)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced network analysis and visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Advanced Network Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Community Detection in Social Network\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# Detect communities using modularity\n",
    "import community as community_louvain  # Note: requires python-louvain\n",
    "try:\n",
    "    partition = community_louvain.best_partition(G_social)\n",
    "    community_colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange']\n",
    "    \n",
    "    # Draw nodes colored by community\n",
    "    for i, (node, community_id) in enumerate(partition.items()):\n",
    "        nx.draw_networkx_nodes(G_social, pos_social, \n",
    "                              nodelist=[node],\n",
    "                              node_color=community_colors[community_id % len(community_colors)],\n",
    "                              node_size=800, alpha=0.9, ax=ax1)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G_social, pos_social, alpha=0.5, ax=ax1)\n",
    "    nx.draw_networkx_labels(G_social, pos_social, font_size=8, font_weight='bold', ax=ax1)\n",
    "    \n",
    "    ax1.set_title(f'Community Detection\\n({len(set(partition.values()))} communities found)')\n",
    "    \n",
    "except ImportError:\n",
    "    # Fallback: manual community assignment\n",
    "    manual_communities = {\n",
    "        'Alice': 0, 'Bob': 0, 'Charlie': 0,  # Engineering\n",
    "        'Diana': 1, 'Eve': 1, 'Grace': 1,    # Marketing\n",
    "        'Frank': 2, 'Henry': 2, 'Jack': 2,   # Sales\n",
    "        'Iris': 1  # Marketing\n",
    "    }\n",
    "    \n",
    "    community_colors = ['red', 'blue', 'green']\n",
    "    for node in G_social.nodes():\n",
    "        community_id = manual_communities.get(node, 0)\n",
    "        nx.draw_networkx_nodes(G_social, pos_social, \n",
    "                              nodelist=[node],\n",
    "                              node_color=community_colors[community_id],\n",
    "                              node_size=800, alpha=0.9, ax=ax1)\n",
    "    \n",
    "    nx.draw_networkx_edges(G_social, pos_social, alpha=0.5, ax=ax1)\n",
    "    nx.draw_networkx_labels(G_social, pos_social, font_size=8, font_weight='bold', ax=ax1)\n",
    "    ax1.set_title('Community Structure\\n(Manual grouping by department)')\n",
    "\n",
    "ax1.axis('off')\n",
    "\n",
    "# 2. Hierarchical Network Layout (Tech Stack)\n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "# Create a hierarchical layout for tech stack\n",
    "hierarchy_levels = {\n",
    "    'Frontend': 0,\n",
    "    'API Gateway': 1,\n",
    "    'Auth Service': 2, 'User Service': 2, 'Order Service': 2,\n",
    "    'Payment Service': 3, 'Notification Service': 3,\n",
    "    'User Database': 3, 'Order Database': 3, 'Auth Database': 3,\n",
    "    'Payment Database': 4, 'Cache': 3, 'Message Queue': 4,\n",
    "    'Email Service': 4, 'External API': 4\n",
    "}\n",
    "\n",
    "# Position nodes by hierarchy level\n",
    "pos_hierarchical = {}\n",
    "level_counts = {}\n",
    "for node, level in hierarchy_levels.items():\n",
    "    if level not in level_counts:\n",
    "        level_counts[level] = 0\n",
    "    level_counts[level] += 1\n",
    "    \n",
    "    # Calculate x position within level\n",
    "    nodes_at_level = [n for n, l in hierarchy_levels.items() if l == level]\n",
    "    x_offset = (level_counts[level] - 1) - (len(nodes_at_level) - 1) / 2\n",
    "    \n",
    "    pos_hierarchical[node] = (x_offset * 2, -level * 2)\n",
    "\n",
    "# Draw the hierarchical network\n",
    "nx.draw_networkx_edges(G_tech, pos_hierarchical, edge_color='darkblue',\n",
    "                      arrows=True, arrowsize=15, arrowstyle='->', \n",
    "                      width=1.5, alpha=0.7, ax=ax2)\n",
    "\n",
    "# Color nodes by layer\n",
    "layer_colors = ['lightgreen', 'orange', 'lightcoral', 'yellow', 'lightgray']\n",
    "for node in G_tech.nodes():\n",
    "    level = hierarchy_levels.get(node, 0)\n",
    "    color = layer_colors[level % len(layer_colors)]\n",
    "    nx.draw_networkx_nodes(G_tech, pos_hierarchical, \n",
    "                          nodelist=[node], node_color=color,\n",
    "                          node_size=800, alpha=0.9, ax=ax2)\n",
    "\n",
    "nx.draw_networkx_labels(G_tech, pos_hierarchical, font_size=7, font_weight='bold', ax=ax2)\n",
    "ax2.set_title('Hierarchical Technology Stack\\n(Layers from frontend to backend)')\n",
    "ax2.axis('off')\n",
    "\n",
    "# 3. Network Flow Analysis\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "# Create a flow network showing information flow\n",
    "G_flow = nx.DiGraph()\n",
    "flow_data = [\n",
    "    ('Data Source', 'ETL Process', 100),\n",
    "    ('ETL Process', 'Data Warehouse', 100),\n",
    "    ('Data Warehouse', 'Analytics', 60),\n",
    "    ('Data Warehouse', 'Reporting', 40),\n",
    "    ('Analytics', 'ML Models', 35),\n",
    "    ('Analytics', 'Dashboards', 25),\n",
    "    ('Reporting', 'Executive Reports', 20),\n",
    "    ('Reporting', 'Operational Reports', 20),\n",
    "    ('ML Models', 'Predictions', 35),\n",
    "    ('Dashboards', 'Business Intelligence', 25)\n",
    "]\n",
    "\n",
    "for source, target, flow in flow_data:\n",
    "    G_flow.add_edge(source, target, flow=flow)\n",
    "\n",
    "pos_flow = nx.spring_layout(G_flow, k=3, iterations=50)\n",
    "\n",
    "# Draw edges with width proportional to flow\n",
    "edges = G_flow.edges()\n",
    "flows = [G_flow[u][v]['flow'] for u, v in edges]\n",
    "max_flow = max(flows)\n",
    "edge_widths = [f/max_flow * 8 for f in flows]\n",
    "\n",
    "nx.draw_networkx_edges(G_flow, pos_flow, width=edge_widths,\n",
    "                      edge_color='steelblue', arrows=True, arrowsize=20,\n",
    "                      arrowstyle='->', alpha=0.7, ax=ax3)\n",
    "\n",
    "# Draw nodes with size proportional to in-flow\n",
    "in_flows = {}\n",
    "for node in G_flow.nodes():\n",
    "    in_flows[node] = sum(G_flow[pred][node]['flow'] for pred in G_flow.predecessors(node))\n",
    "    if in_flows[node] == 0:  # Source nodes\n",
    "        in_flows[node] = 100\n",
    "\n",
    "node_sizes = [in_flows[node] * 8 for node in G_flow.nodes()]\n",
    "nx.draw_networkx_nodes(G_flow, pos_flow, node_size=node_sizes,\n",
    "                      node_color='lightblue', alpha=0.9, ax=ax3)\n",
    "\n",
    "nx.draw_networkx_labels(G_flow, pos_flow, font_size=8, font_weight='bold', ax=ax3)\n",
    "\n",
    "# Add flow labels on edges\n",
    "edge_labels = {(u, v): f\"{G_flow[u][v]['flow']}\" for u, v in G_flow.edges()}\n",
    "nx.draw_networkx_edge_labels(G_flow, pos_flow, edge_labels, font_size=7, ax=ax3)\n",
    "\n",
    "ax3.set_title('Data Flow Network\\n(Edge width = flow volume)')\n",
    "ax3.axis('off')\n",
    "\n",
    "# 4. Influence Network Analysis\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Calculate influence metrics for citation network\n",
    "influence_scores = {}\n",
    "for node in G_citation.nodes():\n",
    "    # Simple influence: citations received + weighted citations given\n",
    "    citations_received = G_citation.in_degree(node, weight='weight')\n",
    "    citations_given = G_citation.out_degree(node, weight='weight')\n",
    "    influence_scores[node] = citations_received * 2 + citations_given  # Weight received citations more\n",
    "\n",
    "# Create influence visualization\n",
    "sorted_papers = sorted(influence_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "papers_sorted = [p[0] for p in sorted_papers]\n",
    "scores_sorted = [p[1] for p in sorted_papers]\n",
    "\n",
    "bars = ax4.barh(papers_sorted, scores_sorted, color='skyblue', alpha=0.8)\n",
    "ax4.set_xlabel('Influence Score')\n",
    "ax4.set_title('Paper Influence Ranking\\n(Based on citation patterns)')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (paper, score) in enumerate(sorted_papers):\n",
    "    ax4.text(score + 0.1, i, f'{score:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# Highlight top 3\n",
    "for i in range(min(3, len(bars))):\n",
    "    bars[i].set_color('orange')\n",
    "    bars[i].set_alpha(1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd304fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network statistics and analysis\n",
    "print(\"Network Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Social Network Analysis\n",
    "print(\"1. SOCIAL NETWORK STATISTICS:\")\n",
    "print(f\"   Nodes (employees): {G_social.number_of_nodes()}\")\n",
    "print(f\"   Edges (connections): {G_social.number_of_edges()}\")\n",
    "print(f\"   Network density: {nx.density(G_social):.3f}\")\n",
    "print(f\"   Average clustering coefficient: {nx.average_clustering(G_social):.3f}\")\n",
    "\n",
    "# Check if network is connected\n",
    "if nx.is_connected(G_social):\n",
    "    print(f\"   Average shortest path length: {nx.average_shortest_path_length(G_social):.2f}\")\n",
    "    print(f\"   Network diameter: {nx.diameter(G_social)}\")\n",
    "else:\n",
    "    print(\"   Network is not fully connected\")\n",
    "\n",
    "# Top employees by centrality\n",
    "print(f\"\\n   Top 3 Most Central Employees:\")\n",
    "degree_cent = nx.degree_centrality(G_social)\n",
    "betweenness_cent = nx.betweenness_centrality(G_social)\n",
    "closeness_cent = nx.closeness_centrality(G_social)\n",
    "\n",
    "top_degree = sorted(degree_cent.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "top_betweenness = sorted(betweenness_cent.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "top_closeness = sorted(closeness_cent.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(f\"     By connections: {', '.join([f'{name} ({score:.3f})' for name, score in top_degree])}\")\n",
    "print(f\"     By betweenness: {', '.join([f'{name} ({score:.3f})' for name, score in top_betweenness])}\")\n",
    "print(f\"     By closeness: {', '.join([f'{name} ({score:.3f})' for name, score in top_closeness])}\")\n",
    "\n",
    "# 2. Technology Network Analysis\n",
    "print(f\"\\n2. TECHNOLOGY DEPENDENCY ANALYSIS:\")\n",
    "print(f\"   Services/components: {G_tech.number_of_nodes()}\")\n",
    "print(f\"   Dependencies: {G_tech.number_of_edges()}\")\n",
    "\n",
    "# Find critical services (high in-degree)\n",
    "in_degrees = dict(G_tech.in_degree())\n",
    "out_degrees = dict(G_tech.out_degree())\n",
    "\n",
    "critical_services = sorted(in_degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "dependency_heavy = sorted(out_degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "print(f\"   Most depended-upon services:\")\n",
    "for service, count in critical_services:\n",
    "    if count > 0:\n",
    "        print(f\"     {service}: {count} services depend on it\")\n",
    "\n",
    "print(f\"   Services with most dependencies:\")\n",
    "for service, count in dependency_heavy:\n",
    "    if count > 0:\n",
    "        print(f\"     {service}: depends on {count} other services\")\n",
    "\n",
    "# Check for cycles (potential circular dependencies)\n",
    "try:\n",
    "    cycles = list(nx.simple_cycles(G_tech))\n",
    "    if cycles:\n",
    "        print(f\"   Circular dependencies detected: {len(cycles)}\")\n",
    "        for cycle in cycles[:3]:  # Show first 3\n",
    "            print(f\"     {' → '.join(cycle + [cycle[0]])}\")\n",
    "    else:\n",
    "        print(f\"   No circular dependencies found ✓\")\n",
    "except:\n",
    "    print(f\"   Cycle detection not available\")\n",
    "\n",
    "# 3. Citation Network Analysis\n",
    "print(f\"\\n3. CITATION NETWORK ANALYSIS:\")\n",
    "print(f\"   Papers: {G_citation.number_of_nodes()}\")\n",
    "print(f\"   Citation relationships: {G_citation.number_of_edges()}\")\n",
    "\n",
    "# Calculate citation statistics\n",
    "total_citations = sum(G_citation[u][v]['weight'] for u, v in G_citation.edges())\n",
    "avg_citations_per_paper = total_citations / G_citation.number_of_nodes()\n",
    "\n",
    "print(f\"   Total citations: {total_citations}\")\n",
    "print(f\"   Average citations per paper: {avg_citations_per_paper:.1f}\")\n",
    "\n",
    "# Find most cited and most citing papers\n",
    "citations_received = {}\n",
    "citations_given = {}\n",
    "\n",
    "for node in G_citation.nodes():\n",
    "    citations_received[node] = sum(G_citation[pred][node]['weight'] \n",
    "                                 for pred in G_citation.predecessors(node))\n",
    "    citations_given[node] = sum(G_citation[node][succ]['weight'] \n",
    "                              for succ in G_citation.successors(node))\n",
    "\n",
    "most_cited = sorted(citations_received.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "most_citing = sorted(citations_given.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(f\"   Most cited papers:\")\n",
    "for paper, count in most_cited:\n",
    "    print(f\"     {paper}: {count} citations received\")\n",
    "\n",
    "print(f\"   Papers citing most others:\")\n",
    "for paper, count in most_citing:\n",
    "    print(f\"     {paper}: {count} citations given\")\n",
    "\n",
    "# 4. Network Patterns and Insights\n",
    "print(f\"\\n4. NETWORK PATTERNS & INSIGHTS:\")\n",
    "\n",
    "# Small world properties\n",
    "try:\n",
    "    # Calculate small-world metrics for social network\n",
    "    clustering = nx.average_clustering(G_social)\n",
    "    if nx.is_connected(G_social):\n",
    "        path_length = nx.average_shortest_path_length(G_social)\n",
    "        # Compare to random network\n",
    "        random_G = nx.erdos_renyi_graph(G_social.number_of_nodes(), \n",
    "                                       G_social.number_of_edges() / (G_social.number_of_nodes() * (G_social.number_of_nodes() - 1) / 2))\n",
    "        random_clustering = nx.average_clustering(random_G)\n",
    "        random_path_length = nx.average_shortest_path_length(random_G) if nx.is_connected(random_G) else 0\n",
    "        \n",
    "        if random_path_length > 0:\n",
    "            small_world_sigma = (clustering / random_clustering) / (path_length / random_path_length)\n",
    "            print(f\"   Small-world coefficient (σ): {small_world_sigma:.3f}\")\n",
    "            if small_world_sigma > 1:\n",
    "                print(f\"     → Social network exhibits small-world properties ✓\")\n",
    "            else:\n",
    "                print(f\"     → Social network does not show clear small-world properties\")\n",
    "except:\n",
    "    print(f\"   Small-world analysis not available\")\n",
    "\n",
    "# Network robustness\n",
    "print(f\"\\n   Network Robustness Analysis:\")\n",
    "if nx.is_connected(G_social):\n",
    "    # Find articulation points (critical nodes)\n",
    "    articulation_points = list(nx.articulation_points(G_social))\n",
    "    if articulation_points:\n",
    "        print(f\"     Critical employees (if removed, network fragments): {', '.join(articulation_points)}\")\n",
    "    else:\n",
    "        print(f\"     No single critical employee (robust network) ✓\")\n",
    "        \n",
    "    # Find bridges (critical connections)\n",
    "    bridges = list(nx.bridges(G_social))\n",
    "    if bridges:\n",
    "        print(f\"     Critical connections: {len(bridges)} bridge(s)\")\n",
    "        for bridge in bridges[:3]:  # Show first 3\n",
    "            print(f\"       {bridge[0]} ↔ {bridge[1]}\")\n",
    "    else:\n",
    "        print(f\"     No critical connections (well-connected network) ✓\")\n",
    "\n",
    "print(f\"\\nNetwork Visualization Best Practices:\")\n",
    "print(\"✓ Use node size to represent importance (degree, centrality)\")\n",
    "print(\"✓ Use edge width to show relationship strength\")\n",
    "print(\"✓ Color nodes by categories or communities\")\n",
    "print(\"✓ Position nodes meaningfully (hierarchy, clustering)\")\n",
    "print(\"✓ Add arrows for directed relationships\")\n",
    "print(\"✓ Include legends for colors and sizes\")\n",
    "print(\"✓ Avoid overcrowded layouts for large networks\")\n",
    "print(\"✓ Consider interactive visualizations for exploration\")\n",
    "\n",
    "print(f\"\\nCommon Network Analysis Applications:\")\n",
    "print(\"• Social networks: Influence, communities, information spread\")\n",
    "print(\"• Technology: Dependencies, architecture, failure analysis\")\n",
    "print(\"• Business: Supply chains, organizational structure\")\n",
    "print(\"• Academic: Citation analysis, collaboration networks\")\n",
    "print(\"• Transportation: Route optimization, network efficiency\")\n",
    "print(\"• Biological: Protein interactions, food webs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4079d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}